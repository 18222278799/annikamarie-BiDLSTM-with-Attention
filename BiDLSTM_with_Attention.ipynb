{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiDLSTM-with-Attention.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annikamarie/annikamarie-BiDLSTM-with-Attention/blob/master/BiDLSTM_with_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvFhysunpSrW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75069b06-24f5-416b-ac65-1c91b93e3026"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i6bBkk-pg3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "%tensorflow_version 1.13.2\n",
        "from tensorflow.python.ops.rnn import bidirectional_dynamic_rnn as bi_rnn\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from tensorflow.contrib.rnn import GRUCell, LSTMCell\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from pprint import pprint\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import gensim as gs\n",
        "import numpy as np\n",
        "import itertools\n",
        "import logging\n",
        "import pickle\n",
        "import json\n",
        "import time\n",
        "import copy\n",
        "import sys\n",
        "import re\n",
        "import os\n",
        "import sklearn as sk \n",
        "\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "\n",
        "def clean_str(s):\n",
        "    return s.strip().lower()\n",
        "\n",
        "def pad_sentences(sentences, padding_word= \"<PAD/>\", forced_sequence_length=541):\n",
        "    \"\"\"Pad setences during training or prediction\"\"\"\n",
        "    if forced_sequence_length is None: # Train\n",
        "        sequence_length = max(len(x) for x in sentences)\n",
        "    else:\n",
        "        logging.critical('This is prediction, reading the trained sequence length')\n",
        "        sequence_length = forced_sequence_length\n",
        "    logging.critical('The maximum length is {}'.format(sequence_length))\n",
        "\n",
        "    padded_sentences = []\n",
        "    for i in range(len(sentences)):\n",
        "        sentence = sentences[i]\n",
        "        num_padding = sequence_length - len(sentence)\n",
        "\n",
        "        if num_padding < 0: # Prediction: cut off the sentence if it is longer than the sequence length\n",
        "            logging.info('This sentence has to be cut off because it is longer than trained sequence length')\n",
        "            padded_sentence = sentence[0:sequence_length]\n",
        "        else:\n",
        "            padded_sentence = sentence + [padding_word] * num_padding\n",
        "        padded_sentences.append(padded_sentence)\n",
        "    return padded_sentences\n",
        "\n",
        "def build_vocab(sentences):\n",
        "    word_counts = Counter(itertools.chain(*sentences))\n",
        "    vocabulary_inv = [word[0] for word in word_counts.most_common()]\n",
        "    vocabulary = {word: index for index, word in enumerate(vocabulary_inv)}\n",
        "    return vocabulary, vocabulary_inv\n",
        "\n",
        "\n",
        "def load_embeddings(vocabulary):\n",
        "    word_embeddings = {}\n",
        "    for word in vocabulary:\n",
        "        word_embeddings[word] = np.random.uniform(-0.25, 0.25, 200)\n",
        "        return word_embeddings\n",
        "\n",
        "\n",
        "def load_data(filename):\n",
        "    df = pd.read_csv(filename,index_col=None, encoding='UTF-8', engine='python', dtype=str)\n",
        "    selected = ['labels', 'text']\n",
        "    df = df.dropna(axis=0, how='any', subset=selected)\n",
        "    df = df.reindex(np.random.permutation(df.index))\n",
        "\n",
        "    labels = sorted(list(set(df[selected[0]].tolist())))\n",
        "    num_labels = len(labels)\n",
        "    one_hot = np.zeros((num_labels, num_labels), int)\n",
        "    np.fill_diagonal(one_hot, 1)\n",
        "    label_dict = dict(zip(labels, one_hot))\n",
        "\n",
        "    x_raw = df[selected[1]].apply(lambda x: clean_str(x).split(' ')).tolist()\n",
        "    y_raw = df[selected[0]].apply(lambda y: label_dict[y]).tolist()\n",
        "\n",
        "    x_raw = pad_sentences(x_raw)\n",
        "    vocabulary, vocabulary_inv = build_vocab(x_raw)\n",
        "\n",
        "    x = np.array([[vocabulary[word] for word in sentence] for sentence in x_raw])\n",
        "    y = np.array(y_raw)\n",
        "    return x, y, vocabulary, vocabulary_inv, df, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEh-IdomyvAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dRNN(cell, inputs, rate, scope='default'):\n",
        "    \"\"\"\n",
        "    This function constructs a layer of dilated RNN.\n",
        "    Inputs:\n",
        "        cell    the dilation operations is implemented independent of the RNN cell.\n",
        "            In theory, any valid tensorflow rnn cell should work.\n",
        "        inputs  the input for the RNN. inputs should be in the form of\n",
        "            a list of 'n_steps' tenosrs. Each has shape (batch_size, input_dims)\n",
        "        rate    the rate here refers to the 'dilations' in the orginal WaveNet paper.\n",
        "        scope   variable scope.\n",
        "    Outputs:\n",
        "        outputs   the outputs from the RNN.\n",
        "    \"\"\"\n",
        "    n_steps = len(inputs)\n",
        "    if rate < 0 or rate >= n_steps:\n",
        "        raise ValueError('The \\'rate\\' variable needs to be adjusted.')\n",
        "    print(\"Building layer: %s, input length: %d, dilation rate: %d, input dim: %d.\" % (\n",
        "        scope, n_steps, rate, inputs[0].get_shape()[1]))\n",
        "\n",
        "    # make the length of inputs divide 'rate', by using zero-padding\n",
        "    EVEN = (n_steps % rate) == 0\n",
        "    if not EVEN:\n",
        "        # Create a tensor in shape (batch_size, input_dims), which all elements are zero.\n",
        "        # This is used for zero padding\n",
        "        zero_tensor = tf.zeros_like(inputs[0])\n",
        "        dialated_n_steps = n_steps // rate + 1\n",
        "        print(\"=====> %d time points need to be padded. \" % (\n",
        "            dialated_n_steps * rate - n_steps))\n",
        "        print(\"=====> Input length for sub-RNN: %d\" % (dialated_n_steps))\n",
        "        for i_pad in range(dialated_n_steps * rate - n_steps):\n",
        "            inputs.append(zero_tensor)\n",
        "    else:\n",
        "        dialated_n_steps = n_steps // rate\n",
        "        print(\"=====> Input length for sub-RNN: %d\" % (dialated_n_steps))\n",
        "\n",
        "    # now the length of 'inputs' divide rate\n",
        "    # reshape it in the format of a list of tensors\n",
        "    # the length of the list is 'dialated_n_steps'\n",
        "    # the shape of each tensor is [batch_size * rate, input_dims]\n",
        "    # by stacking tensors that \"colored\" the same\n",
        "\n",
        "    # Example:\n",
        "    # n_steps is 5, rate is 2, inputs = [x1, x2, x3, x4, x5]\n",
        "    # zero-padding --> [x1, x2, x3, x4, x5, 0]\n",
        "    # we want to have --> [[x1; x2], [x3; x4], [x_5; 0]]\n",
        "    # which the length is the ceiling of n_steps/rate\n",
        "    dilated_inputs = [tf.concat(inputs[i * rate:(i + 1) * rate],\n",
        "                                axis=0) for i in range(dialated_n_steps)]\n",
        "\n",
        "    # building a dialated RNN with reformated (dilated) inputs\n",
        "    dilated_outputs, _ = tf.contrib.rnn.static_rnn(\n",
        "        cell, dilated_inputs,\n",
        "        dtype=tf.float32, scope=scope)\n",
        "\n",
        "    # reshape output back to the input format as a list of tensors with shape [batch_size, input_dims]\n",
        "    # split each element of the outputs from size [batch_size*rate, input_dims] to\n",
        "    # [[batch_size, input_dims], [batch_size, input_dims], ...] with length = rate\n",
        "    splitted_outputs = [tf.split(output, rate, axis=0)\n",
        "                        for output in dilated_outputs]\n",
        "    unrolled_outputs = [output\n",
        "                        for sublist in splitted_outputs for output in sublist]\n",
        "    # remove padded zeros\n",
        "    outputs = unrolled_outputs[:n_steps]\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def multi_dRNN_with_dilations(cells, inputs, dilations):\n",
        "    \"\"\"\n",
        "    This function constucts a multi-layer dilated RNN.\n",
        "    Inputs:\n",
        "        cells      A list of RNN cells.\n",
        "        inputs     A list of 'n_steps' tensors, each has shape (batch_size, input_dims).\n",
        "        dilations  A list of integers with the same length of 'cells' indicates the dilations for each layer.\n",
        "    Outputs:\n",
        "        x     A list of 'n_steps' tensors, as the outputs for the top layer of the multi-dRNN.\n",
        "    \"\"\"\n",
        "    assert (len(cells) == len(dilations))\n",
        "    x = copy.copy(inputs)\n",
        "    for cell, dilation in zip(cells, dilations):\n",
        "        scope_name = \"multi_dRNN_dilation_%d\" % dilation\n",
        "        x = dRNN(cell, x, dilation, scope=scope_name)\n",
        "    return x\n",
        "\n",
        "def _contruct_cells(hidden_structs, cell_type,dropouts):\n",
        "    \"\"\"\n",
        "    This function contructs a list of cells.\n",
        "    \"\"\"\n",
        "    # error checking\n",
        "    if cell_type not in [\"RNN\", \"LSTM\", \"GRU\"]:\n",
        "        raise ValueError(\"The cell type is not currently supported.\")\n",
        "\n",
        "    # define cells\n",
        "    cells = []\n",
        "    for hidden_dims in hidden_structs:\n",
        "        if cell_type == \"RNN\":\n",
        "            cell = tf.contrib.rnn.BasicRNNCell(hidden_dims)\n",
        "        elif cell_type == \"LSTM\":\n",
        "            cell = tf.contrib.rnn.BasicLSTMCell(hidden_dims)\n",
        "            cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=dropouts)\n",
        "        elif cell_type == \"GRU\":\n",
        "            cell = tf.contrib.rnn.GRUCell(hidden_dims)\n",
        "        cells.append(cell)\n",
        "\n",
        "    return cells\n",
        "\n",
        "\n",
        "def _rnn_reformat(embedded_chars, embedding_dim, n_steps):\n",
        "    \"\"\"\n",
        "    This function reformat input to the shape that standard RNN can take.\n",
        "\n",
        "    Inputs:\n",
        "        x    a tensor of shape (batch_size, n_steps, input_dims).\n",
        "    Outputs:\n",
        "        x_reformat   a list of 'n_steps' tenosrs, each has shape (batch_size, input_dims).\n",
        "    \"\"\"\n",
        "    # permute batch_size and n_steps\n",
        "    x_ = tf.transpose(embedded_chars, [1, 0, 2])\n",
        "    # reshape to (n_steps*batch_size, input_dims)\n",
        "    x_ = tf.reshape(x_, [-1, embedding_dim])\n",
        "    # split to get a list of 'n_steps' tensors of shape (batch_size, input_dims)\n",
        "    x_reformat = tf.split(x_, n_steps, 0)\n",
        "\n",
        "    return x_reformat\n",
        "\n",
        "\n",
        "def drnn_classification(embedded_chars,\n",
        "                        hidden_structs,\n",
        "                        dilations,\n",
        "                        n_steps,\n",
        "                        dropouts,\n",
        "                        embedding_dim,\n",
        "                        cell_type=\"RNN\"):\n",
        "\n",
        "    \"\"\"This function construct a multilayer dilated RNN for classifiction.\n",
        "    Inputs:\n",
        "        x      a tensor of shape (batch_size, n_steps, input_dims).\n",
        "        hidden_structs   a list, each element indicates the hidden node dimension of each layer.\n",
        "        dilations   a list, each element indicates the dilation of each layer.\n",
        "        n_steps    the length of the sequence.\n",
        "        input_dims     the input dimension.\n",
        "        cell_type    the type of the RNN cell, should be in [\"RNN\", \"LSTM\", \"GRU\"].\n",
        "\n",
        "    Outputs:\n",
        "        pred   the prediction logits at the last timestamp and the last layer of the RNN.\n",
        "                'pred' does not pass any output activation functions.\"\"\"\n",
        "\n",
        "    # error checking\n",
        "    assert (len(hidden_structs) == len(dilations))\n",
        "\n",
        "    # reshape inputs\n",
        "    x_reformat = _rnn_reformat(embedded_chars, embedding_dim, n_steps)\n",
        "\n",
        "    # construct a list of cells\n",
        "    cells = _contruct_cells(hidden_structs, cell_type,dropouts)\n",
        "\n",
        "    # define dRNN structures\n",
        "    layer_outputs = multi_dRNN_with_dilations(cells, x_reformat, dilations)\n",
        "\n",
        "    return layer_outputs\n",
        "\n",
        "#######################################################################################################################\n",
        "#######################################################################################################################\n",
        "\n",
        "def attention(inputs, attention_size, time_major=True, return_alphas=False):\n",
        "    \"\"\"\n",
        "    Attention mechanism layer which reduces RNN/Bi-RNN outputs with Attention vector.\n",
        "\n",
        "    The idea was proposed in the article by Z. Yang et al., \"Hierarchical Attention Networks\n",
        "     for Document Classification\", 2016: http://www.aclweb.org/anthology/N16-1174.\n",
        "    Variables notation is also inherited from the article and has been used as inspiration for this attention. \n",
        "\n",
        "    Args:\n",
        "        inputs: The Attention inputs.\n",
        "            Matches outputs of RNN/Bi-RNN layer (not final state):\n",
        "                In case of RNN, this must be RNN outputs `Tensor`:\n",
        "                    If time_major == False (default), this must be a tensor of shape:\n",
        "                        `[batch_size, max_time, cell.output_size]`.\n",
        "                    If time_major == True, this must be a tensor of shape:\n",
        "                        `[max_time, batch_size, cell.output_size]`.\n",
        "                In case of Bidirectional RNN, this must be a tuple (outputs_fw, outputs_bw) containing the forward and\n",
        "                the backward RNN outputs `Tensor`.\n",
        "                    If time_major == False (default),\n",
        "                        outputs_fw is a `Tensor` shaped:\n",
        "                        `[batch_size, max_time, cell_fw.output_size]`\n",
        "                        and outputs_bw is a `Tensor` shaped:\n",
        "                        `[batch_size, max_time, cell_bw.output_size]`.\n",
        "                    If time_major == True,\n",
        "                        outputs_fw is a `Tensor` shaped:\n",
        "                        `[max_time, batch_size, cell_fw.output_size]`\n",
        "                        and outputs_bw is a `Tensor` shaped:\n",
        "                        `[max_time, batch_size, cell_bw.output_size]`.\n",
        "        attention_size: Linear size of the Attention weights.\n",
        "        time_major: The shape format of the `inputs` Tensors.\n",
        "            If true, these `Tensors` must be shaped `[max_time, batch_size, depth]`.\n",
        "            If false, these `Tensors` must be shaped `[batch_size, max_time, depth]`.\n",
        "            Using `time_major = True` is a bit more efficient because it avoids\n",
        "            transposes at the beginning and end of the RNN calculation.  However,\n",
        "            most TensorFlow data is batch-major, so by default this function\n",
        "            accepts input and emits output in batch-major form.\n",
        "        return_alphas: Whether to return attention coefficients variable along with layer's output.\n",
        "            Used for visualization purpose.\n",
        "    Returns:\n",
        "        The Attention output `Tensor`.\n",
        "        In case of RNN, this will be a `Tensor` shaped:\n",
        "            `[batch_size, cell.output_size]`.\n",
        "        In case of Bidirectional RNN, this will be a `Tensor` shaped:\n",
        "            `[batch_size, cell_fw.output_size + cell_bw.output_size]`.\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = tf.stack(inputs, axis=0)\n",
        "\n",
        "    if time_major:\n",
        "        # (T,B,D) => (B,T,D)\n",
        "        inputs = tf.transpose(inputs, [1, 0, 2])\n",
        "\n",
        "    hidden_size = inputs.shape[2].value  # D value - hidden size of the RNN layer\n",
        "\n",
        "    # Trainable parameters\n",
        "    w_omega = tf.Variable(tf.random_normal([hidden_size, attention_size], stddev=0.1))\n",
        "    b_omega = tf.Variable(tf.random_normal([attention_size], stddev=0.1))\n",
        "    u_omega = tf.Variable(tf.random_normal([attention_size], stddev=0.1))\n",
        "\n",
        "    with tf.name_scope('Variable'):\n",
        "        # Applying fully connected layer with non-linear activation to each of the B*T timestamps;\n",
        "        # the shape of `v` is (B,T,D)*(D,A)=(B,T,A), where A=attention_size\n",
        "        v = tf.tanh(tf.tensordot(inputs, w_omega, axes=1) + b_omega)\n",
        "\n",
        "    # For each of the timestamps its vector of size A from `v` is reduced with `u` vector\n",
        "    vu = tf.tensordot(v, u_omega, axes=1, name='vu')  # (B,T) shape\n",
        "    alphas = tf.nn.softmax(vu, name='alphas')  # (B,T) shape\n",
        "\n",
        "    # Output of (Bi-)RNN is reduced with attention vector; the result has (B,D) shape\n",
        "    output = tf.reduce_sum(inputs * tf.expand_dims(alphas, -1), 1)\n",
        "\n",
        "    if not return_alphas:\n",
        "        return output\n",
        "    else:\n",
        "        return output, alphas\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8RpjZEaqDXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/Folder/your_file.csv'\n",
        "\n",
        "# Tokenize tweets and map to one_hot labels\n",
        "x_, y_, vocabulary,vocabulary_inv,dataframe ,labels = load_data(path)\n",
        "word_embeddings = load_embeddings(vocabulary)\n",
        "print(\"===> Loaded Data and Parameters\")\n",
        "\n",
        "# split data\n",
        "x, x_test, y, y_test = train_test_split(x_, y_, test_size=0.2, random_state=42)\n",
        "x_train, x_dev, y_train, y_dev = train_test_split(x, y, test_size=0.3)\n",
        "\n",
        "logging.info('x_train: {}, x_dev: {}, x_test: {}'.format(len(x_train), len(x_dev), len(x_test)))\n",
        "logging.info('y_train: {}, y_dev: {}, y_test: {}'.format(len(y_train), len(y_dev), len(y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzAzDfE-p6In",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# configurations\n",
        "n_steps = x_train.shape[1]\n",
        "n_classes = 3\n",
        "vocabulary_size = len(vocabulary)\n",
        "EMBEDDING_DIM = 250\n",
        "ATTENTION_SIZE = 250\n",
        "HIDDEN_SIZE = 250\n",
        "num_layers = 2\n",
        "num_hidden = 250\n",
        "MODEL_PATH = './BLGSN_1000'\n",
        "DELTA = 0.5\n",
        "KEEP_PROB = 0.5\n",
        "batch_size = 64\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 10\n",
        "INDEX_FROM = 0\n",
        "epochs = 10\n",
        "dropout_keep_prob=0.5\n",
        "\n",
        "# model config\n",
        "cell_type = \"LSTM\"\n",
        "assert(cell_type in [\"RNN\", \"LSTM\", \"GRU\"])\n",
        "hidden_structs = [250,250]\n",
        "dilations = [1,2]\n",
        "assert(len(hidden_structs) == len(dilations))\n",
        "\n",
        "with tf.name_scope('Inputs'):\n",
        "    x = tf.placeholder(tf.int32, [None, n_steps], name='batch_ph')\n",
        "    y = tf.placeholder(tf.float32, [None, n_classes], name='target_ph')\n",
        "    keep_prob_ph = tf.placeholder(tf.float32, name='keep_prob_ph')\n",
        "\n",
        "with tf.name_scope('Embedding_layer'):\n",
        "    embeddings_var = tf.Variable(tf.random_uniform([vocabulary_size, EMBEDDING_DIM], -1.0,1.0), trainable=True)\n",
        "    embedded_chars = tf.nn.embedding_lookup(embeddings_var, x, max_norm=None, validate_indices=True, partition_strategy='mod')\n",
        "\n",
        "for layer in range(num_layers):\n",
        "  cell_fw = tf.contrib.rnn.LSTMCell(num_hidden)\n",
        "  forward = tf.contrib.rnn.DropoutWrapper(cell_fw, input_keep_prob=dropout_keep_prob)\n",
        "\n",
        "  cell_bw = tf.contrib.rnn.LSTMCell(num_hidden)\n",
        "  backward = tf.contrib.rnn.DropoutWrapper(cell_bw, input_keep_prob=dropout_keep_prob)\n",
        "\n",
        "with tf.name_scope('Bi_Directional_Layer'):\n",
        "            # forward and backward outputs are concatenated\n",
        "            outputs, output_states = tf.nn.bidirectional_dynamic_rnn(forward,backward, inputs=embedded_chars,dtype=tf.float32)\n",
        "            last_state_fw, last_state_bw = outputs\n",
        "            add_together = tf.math.add(last_state_fw, last_state_bw)\n",
        "\n",
        "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "pred = drnn_classification(embedded_chars, hidden_structs, dilations, n_steps, KEEP_PROB, EMBEDDING_DIM,cell_type)\n",
        "\n",
        "with tf.name_scope('Attention_layer'):\n",
        "    attention_output, alphas = attention(pred, ATTENTION_SIZE, return_alphas=True)\n",
        "    tf.summary.histogram('alphas', alphas)\n",
        "    drop = tf.nn.dropout(attention_output, keep_prob_ph)\n",
        "\n",
        "with tf.name_scope('Fully_connected_layer'):\n",
        "    W = tf.Variable(tf.truncated_normal([HIDDEN_SIZE, n_classes], stddev=0.1))\n",
        "    b = tf.Variable(tf.constant(0., shape=[n_classes]))\n",
        "    y_hat = tf.nn.xw_plus_b(drop, W, b)\n",
        "    predictions = tf.argmax(input=y_hat, axis=1, name='predictions')\n",
        "    print(y_hat)\n",
        "    probs = tf.nn.softmax(y_hat)\n",
        "    tf.summary.histogram('W', W)\n",
        "\n",
        "with tf.name_scope('Loss'):\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_hat, labels=y))\n",
        "    tf.summary.scalar('loss', loss)\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)\n",
        "\n",
        "with tf.name_scope('Accuracy'):\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.round(tf.nn.softmax(y_hat)), y), tf.float32))\n",
        "    tf.summary.scalar('accuracy', accuracy)\n",
        "\n",
        "with tf.name_scope('correct_predictions'):\n",
        "    correct_predictions = tf.equal(tf.argmax(input=y, axis=1), predictions)\n",
        "    num_correct = tf.reduce_sum(input_tensor=tf.cast(correct_predictions, 'float'),name='correct_predictions')\n",
        "\n",
        "merged = tf.summary.merge_all()\n",
        "print(\"Loaded Model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKfTaOfjqgb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch generators\n",
        "def batch_generator(X, y, batch_size):\n",
        "    \"\"\"batch generator\"\"\"\n",
        "    size = X.shape[0]\n",
        "    X_copy = X.copy()\n",
        "    y_copy = y.copy()\n",
        "    indices = np.arange(size)\n",
        "    np.random.shuffle(indices)\n",
        "    X_copy = X_copy[indices]\n",
        "    y_copy = y_copy[indices]\n",
        "    i = 0\n",
        "    while True:\n",
        "        if i + batch_size <= size:\n",
        "            yield X_copy[i:i + batch_size], y_copy[i:i + batch_size]\n",
        "            i += batch_size\n",
        "        else:\n",
        "            i = 0\n",
        "            indices = np.arange(size)\n",
        "            np.random.shuffle(indices)\n",
        "            X_copy = X_copy[indices]\n",
        "            y_copy = y_copy[indices]\n",
        "            continue\n",
        "            \n",
        "train_batch_generator = batch_generator(x_train, y_train, batch_size)\n",
        "test_batch_generator = batch_generator(x_dev, y_dev, batch_size)\n",
        "predict_generator = batch_generator(x_test, y_test, batch_size)\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(\"Start learning...\")\n",
        "    for epoch in range(epochs):\n",
        "        loss_train = 0\n",
        "        loss_val = 0\n",
        "        loss_test = 0\n",
        "        accuracy_train = 0\n",
        "        accuracy_val = 0\n",
        "        accuracy_test = 0\n",
        "        train_loss_l = []\n",
        "        val_loss_l = []\n",
        "\n",
        "        print(\"epoch: {}\\t\".format(epoch), end=\"\")\n",
        "\n",
        "        # Training\n",
        "        num_batches = x_train.shape[0] // batch_size\n",
        "        for b in tqdm(range(num_batches)):\n",
        "            x_batch, y_batch = next(train_batch_generator)\n",
        "            loss_tr, acc, _, summary = sess.run([loss, accuracy, optimizer, merged],\n",
        "                                                feed_dict={x: x_batch,\n",
        "                                                           y: y_batch,\n",
        "                                                           keep_prob_ph: 0.5})\n",
        "            train_loss_l.append(loss_tr)\n",
        "            accuracy_train += acc\n",
        "            loss_train = loss_tr * DELTA + loss_train * (1 - DELTA)\n",
        "        accuracy_train /= num_batches\n",
        "            \n",
        "        # Validation\n",
        "        num_batches = x_dev.shape[0] // batch_size\n",
        "        for b in tqdm(range(num_batches)):\n",
        "            x_batch, y_batch = next(test_batch_generator)\n",
        "            val_loss, val_acc, summary = sess.run([loss, accuracy, merged],\n",
        "                                                     feed_dict={x: x_batch,\n",
        "                                                                y: y_batch,\n",
        "                                                                keep_prob_ph: 1.0})\n",
        "            val_loss_l.append(val_loss)\n",
        "            accuracy_val += val_acc\n",
        "            loss_val += val_loss\n",
        "        accuracy_val /= num_batches\n",
        "        loss_val /= num_batches\n",
        "\n",
        "        print(\"loss: {:.3f}, val_loss: {:.3f}, acc: {:.3f}, val_acc: {:.3f}\".format(\n",
        "            loss_train, loss_val, accuracy_train, accuracy_val\n",
        "        ))\n",
        "\n",
        "    # predict x_test\n",
        "    num_batches = x_test.shape[0] // batch_size\n",
        "    predict_correct = 0\n",
        "    for batch in tqdm(range(num_batches)):\n",
        "        x_batch, y_batch = next(predict_generator)\n",
        "        loss_pred, acc_pred, n_correct,y_pred = sess.run([loss,accuracy,num_correct, predictions], \n",
        "                                                         feed_dict={x: x_batch,\n",
        "                                                                    y: y_batch,\n",
        "                                                                    keep_prob_ph : 0.5 })     \n",
        "        \n",
        "    y_true = np.argmax(y_batch,1)\n",
        "    print(y_true)\n",
        "    print(y_pred)\n",
        "        \n",
        "    print(\"Precision\", sk.metrics.precision_score(y_true, y_pred,average='weighted'))\n",
        "    print(\"Recall\", sk.metrics.recall_score(y_true, y_pred,average='weighted'))\n",
        "    print(\"f1_score\", sk.metrics.f1_score(y_true, y_pred,average='weighted'))\n",
        "    print(\"confusion_matrix\")\n",
        "    print(sk.metrics.confusion_matrix(y_true, y_pred))\n",
        "    \n",
        "  \n",
        "    # get probability distribution for labels\n",
        "    num_batches = x_dev.shape[0] // batch_size\n",
        "    for b in tqdm(range(num_batches)):\n",
        "        x_batch, y_batch = next(test_batch_generator)\n",
        "        predictions_2 = sess.run(probs, feed_dict={x: x_batch,\n",
        "                                                   y: y_batch,\n",
        "                                                   keep_prob_ph: 1.0})\n",
        "    \n",
        "    saver.save(sess, MODEL_PATH)\n",
        "    print(\"Run 'tensorboard --logdir=./logdir' to checkout tensorboard logs.\")\n",
        "    plt.plot(train_loss_l)\n",
        "    plt.plot(val_loss_l)\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}